# Réu du 11/03

## Ce qu'on a fait :

#### Nina : 

Les réseaux de neurones convolutifs => fonctionnent par couches avec des filtrages.

Plien de couches différentes => couche de filtrage et couche de mise en commun entre les couches.

#### Jules : 

Aussi les réseaux de neurones :   
Entrée : tous les pixels de l'image,  
a regardé comment fonctionnent les poids, fonctions d'activations, biais dans les réseaux de neurones ainsi que le fonctionnement général

#### Jades :

À réétudier le filtre de gabor :  linéaire, de seuil, d'énergie de ?? / le critère de fisher permet de 

moment complexe => dérivée

#### Lucas :

C4.5 ds le traiteent de l'image ?

On part de l'image et on extrait un descripteur => on a une image et on détecte les 3 couleurs les plus présente dans l'image. On créé donc un descripteur couleur. On peut faire pareil avec une forme => on peut récupérer le centre de gravité. Les vecteurs qu'on a créé nous permettent de classifer.

#### Conseils : 

Important de bien comprendre l'abstract qui comporte le coeur du papier;
Attention dans les articles pas forcement tout tout creuser pcq au final c'est pas important 

## Réseaux de neurones : 

### Convolutifs 

Réseaux convolutifs => en vrai pas horrible, c'est juste une somme de produit. On sait aussi faire un produit de convolution entre un filtre et une image. On balade le filtre sur toute l'image (Ex img de 1000x1000 et on parcourt un filtre de taille 5x5 sur toute l'image. Chaque carré filitré correspond à 1 px). 

L'image est en 2D, on a des fréquences verticales et horizontales mais aussi diagonales. La manière dont je construit le filtre permet de détecter des variations selon les lignes/colones ou diagonales. Et ça ça aide à reconnaitre les objets. Les filtres sont sensibles à des motifs particuliers. Il faut donc utiliser les filtres adéquats. Les filtres ont tendence à reconnaitre 1 forme précise.

Les plusieurs couches permettent d'affiner la recherche. (Ex: 1 visage => Avant un truc rond, puis un truc rond avec des trous noirs au niveau des yeux, …)

Deep Learning => bcp de couches (500/1000 couches …)

On s'inspire de la vrai vie avec des cables (ds les neurones). Un neurone va être plus ou moins activé et il active d'autant le neurone suivant. Le neurone $n_{+1}$ recoit l'activation de tous les neurones précédants.

Pour ces résraux on a une base d'apprentissage, avec une image d'un chien on sait que c'est un chien. Si à la sortie le neurone qui reconnait un chien n'est pas activé, on va rétropropager pour changer les poids dans les réseaux de neurones.

Nous on va commencer avec une disjonction simple : Bolet / pas Bolet.

Souvent on part de poids aléatoires ou de réseaux connus qui ont déjà des poids.

L'algo de rétropropagration : 

Il calcule quel est l'influence du poids sur le résultat. Si en augmentant le poids la réponse est meilleure et bah on l'augmente (resp. diminution).

### Non convolutif :

On traite les pixels comme des pixels; on ne filtre pas. Comme tous les px sont en entrée, on cherche à diminuer la résolution de l'image.

Le deep learning est assez gourmant en coefficient (en millions), du coup on prie pour que le résultat converge. Les apprentissages sont longs. On cherche alors des compromis entre le deep learning et le light deep learning

## TODO :

- On bosse encore sur nos articles, les choses qui nous donnent envie
- aller plus loin dans la recherche du dataset 
- Faire des réus entre nous pour parler de nos recherches, pas forcément attendre les réus avec KID

## Prochaine réu

- Vendredi 19/03  : 11h30
- Avec KID : Vendredi 19/03 : 14h30

